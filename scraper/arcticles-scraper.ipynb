{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scraping ⛏️\n",
    "\n",
    "Since this is my first attempt at scraping data, I will begin by examining only trustworthy news outlets. I believe that starting with the BBC would be the easiest, as I did my research and found out that they were ranked as the 4th most trusted news by Americans. Even though we live in Europe, I choose to believe this statistic. Later on, I plan to expand my list of trustworthy sources, but for now, this is my starting point, so bare with me.\n",
    "\n",
    "First, lets begin by importing the libraries, we are going to use today and checking each of their versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn version: 1.6.1\n",
      "pandas version: 2.2.3\n",
      "seaborn version: 0.13.2\n",
      "requests version: 2.31.0\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "print(\"scikit-learn version:\", sklearn.__version__)     # 1.6.1\n",
    "print(\"pandas version:\", pd.__version__)                # 2.2.3\n",
    "print(\"seaborn version:\", seaborn.__version__)          # 0.13.2\n",
    "print(\"requests version:\", requests.__version__)        # 2.31.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets get to the actual thing!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No articles were scraped. Check your CSS selectors.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "import requests\n",
    "from bs4 import BeautifulSoup  # Correct usage of BeautifulSoup\n",
    "\n",
    "# Print library versions\n",
    "print(\"scikit-learn version:\", sklearn.__version__)  # 1.6.1\n",
    "print(\"pandas version:\", pd.__version__)             # 2.2.3\n",
    "print(\"seaborn version:\", seaborn.__version__)       # 0.13.2\n",
    "print(\"requests version:\", requests.__version__)     # 2.31.0\n",
    "\n",
    "# Function to scrape titles and links\n",
    "def scrape_news_titles_and_links(url, title_selector, link_selector):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')  # Proper usage of BeautifulSoup\n",
    "        titles = [title.get_text(strip=True) for title in soup.select(title_selector)]\n",
    "        links = [link['href'] for link in soup.select(link_selector) if link.has_attr('href')]\n",
    "\n",
    "        # Combine titles and links into a list of dictionaries\n",
    "        articles = [{\"Title\": t, \"Link\": l} for t, l in zip(titles, links)]\n",
    "        return articles\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []\n",
    "\n",
    "# Example website (BBC News)\n",
    "url = \"https://www.bbc.com/news\"\n",
    "\n",
    "# Define CSS selectors for titles and links\n",
    "title_selector = \".gs-c-promo-heading__title\"  # Adjusted CSS selector for titles\n",
    "link_selector = \".gs-c-promo-heading\"         # Adjusted CSS selector for links\n",
    "\n",
    "# Scrape titles and links\n",
    "articles = scrape_news_titles_and_links(url, title_selector, link_selector)\n",
    "\n",
    "# Convert the articles to a DataFrame and save to a CSV file\n",
    "if articles:\n",
    "    data = pd.DataFrame(articles)\n",
    "    data.to_csv(\"truthful_news_titles_and_links.csv\", index=False)\n",
    "    print(\"Article metadata saved to 'truthful_news_titles_and_links.csv'\")\n",
    "    print(data.head())\n",
    "else:\n",
    "    print(\"No articles were scraped. Check your CSS selectors.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
